{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
      "metadata": {
        "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
      },
      "source": [
        "# Assignment: Data Wrangling\n",
        "## `! git clone https://github.com/DS3001/wrangling`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "c4ZblKZrWgtQ"
      },
      "id": "c4ZblKZrWgtQ",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/DS3001/wrangling"
      ],
      "metadata": {
        "id": "VsdngQAuWAi8",
        "outputId": "b6a8a8ba-3a7c-4c7b-90db-d1605c0a9da5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "VsdngQAuWAi8",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wrangling'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (34/34), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 75 (delta 27), reused 10 (delta 10), pack-reused 41\u001b[K\n",
            "Receiving objects: 100% (75/75), 6.25 MiB | 13.80 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5735a4d4-8be8-433a-a351-70eb8002e632",
      "metadata": {
        "id": "5735a4d4-8be8-433a-a351-70eb8002e632"
      },
      "source": [
        "**Q1.** Open the \"tidy_data.pdf\" document in the repo, which is a paper called Tidy Data by Hadley Wickham.\n",
        "\n",
        "  1. Read the abstract. What is this paper about?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Hadley Wickam's paper \"Tidy Data\" is about a small, but important, component of data cleaning: data tidying. He establishes a specific framework for dealing with un-tidy datasets (each variable is a column, each observation is a row, and each type of observational unit\n",
        "is a table), so that more consistent data structures can be developed."
      ],
      "metadata": {
        "id": "hawVnwrS-xcW"
      },
      "id": "hawVnwrS-xcW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "  2. Read the introduction. What is the \"tidy data standard\" intended to accomplish?"
      ],
      "metadata": {
        "id": "vGrTv6Oi-3Ll"
      },
      "id": "vGrTv6Oi-3Ll"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The tidy data standard is intended to facilitate\n",
        "initial exploration and analysis of the data, and to simplify the development of data analysis tools that work well together. A standard makes initial data cleaning easier because you don’t need to start from scratch and reinvent the wheel every time."
      ],
      "metadata": {
        "id": "brSYF_sdAQ25"
      },
      "id": "brSYF_sdAQ25"
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Read the intro to section 2. What does this sentence mean: \"Like families, tidy datasets are all alike but every messy dataset is messy in its own way.\" What does this sentence mean: \"For a given dataset, it’s usually easy to figure out what are observations and what are variables, but it is surprisingly difficult to precisely define variables and observations in general.\""
      ],
      "metadata": {
        "id": "JuUXmM1rAEDo"
      },
      "id": "JuUXmM1rAEDo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The first sentence explains that messy data often presents unique or inconsistent problems, while properties of clean data remain similar and consistent.\n",
        "\n",
        "> The second sentence explains that the semantics of a a data frame's structure is self-explanatory (e.g. rows = observations, columbs = variables). However, in practice, identifying variables from observations can be a somewhat subjective decision made by the data analyst. This could ultimately cause inconsistencies between different analysts' \"cleaned\" data."
      ],
      "metadata": {
        "id": "InN-nKe4A1C1"
      },
      "id": "InN-nKe4A1C1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Read Section 2.2. How does Wickham define values, variables, and observations?"
      ],
      "metadata": {
        "id": "UZhpz0eaAusW"
      },
      "id": "UZhpz0eaAusW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **values:** numbers (if quantitative) or strings (if qualitative)\n",
        "\n",
        "> **variables:** all values that measure the same underlying attribute (like height, temperature, duration) across units\n",
        "\n",
        "> **observations:**  all values measured on the same unit (like a person, or a day, or a race) across attributes"
      ],
      "metadata": {
        "id": "zeVSOX5qDaBs"
      },
      "id": "zeVSOX5qDaBs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. How is \"Tidy Data\" defined in section 2.3?"
      ],
      "metadata": {
        "id": "hXJJeSfMDZNC"
      },
      "id": "hXJJeSfMDZNC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **tidy data:** a standard way of mapping the meaning of a dataset to its structure\n",
        "\n",
        "> Data is tidy if:\n",
        "1. Each variable forms a column.\n",
        "2. Each observation forms a row.\n",
        "3. Each type of observational unit forms a table."
      ],
      "metadata": {
        "id": "0PqwAZ7QEBIf"
      },
      "id": "0PqwAZ7QEBIf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Read the intro to Section 3 and Section 3.1. What are the 5 most common problems with messy datasets? Why are the data in Table 4 messy? What is \"melting\" a dataset?"
      ],
      "metadata": {
        "id": "XUkE-cyBEAWE"
      },
      "id": "XUkE-cyBEAWE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> The 5 most common problems with messy datasets are:\n",
        "1. Column headers are values, not variable names.\n",
        "2. Multiple variables are stored in one column.\n",
        "3. Variables are stored in both rows and columns.\n",
        "4. Multiple types of observational units are stored in the same table.\n",
        "5. A single observational unit is stored in multiple tables.\n",
        "\n",
        "> Table 4 displays data where variables form both the rows and columns, and column headers are values, not variable names. This dataset has three variables: `religion`, `income`, and `frequency`. However, only `religion` and `frequency` are explicitly displayed, while `income` is hidden.\n",
        "\n",
        "> Melting, or stacking, a dataset is the process of turning columns into rows."
      ],
      "metadata": {
        "id": "40rh43vIEUFP"
      },
      "id": "40rh43vIEUFP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Why, specifically, is table 11 messy but table 12 tidy and \"molten\"?"
      ],
      "metadata": {
        "id": "KehO15aTETa0"
      },
      "id": "KehO15aTETa0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Table 11 is messy because it has variables in\n",
        "individual columns (`id`, `year`, `month`), spread across columns (`day`, d1–d31) and across rows\n",
        "(`tmin`, `tmax`). Additionally, months with less than 31 days have structural missing values for the last day(s) of the month. The element column is not a variable; it stores the names of variables.\n",
        "\n",
        "> In contrast, in Table 12, each row represents the meteorological measurements for a single day. There are two measured variables: `tmin` (minimum temp) and 'tmax' (maximum temp); all other variables are fixed."
      ],
      "metadata": {
        "id": "l6hY2pJWGPkn"
      },
      "id": "l6hY2pJWGPkn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Read Section 6. What is the \"chicken-and-egg\" problem with focusing on tidy data? What does Wickham hope happens in the future with further work on the subject of data wrangling?"
      ],
      "metadata": {
        "id": "uIvw90Z9GOpn"
      },
      "id": "uIvw90Z9GOpn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **chicken-and-egg problem with tidy data:** If we consider tidy data as valuable as the tools designed for it, then the effectiveness of tidy tools is closely tied to tidy data. This connection means that if we try to change data structures or tools separately, it might not necessarily enhance our work process.\n",
        "\n",
        "> Wickham hopes that the tidy data framework is\n",
        "not one a \"false start,\" but he also doesn’t see it as the final solution. He hopes others will build\n",
        "on this framework to develop even better data storage strategies and tools."
      ],
      "metadata": {
        "id": "9U_ei148X-2M"
      },
      "id": "9U_ei148X-2M"
    },
    {
      "cell_type": "markdown",
      "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
      "metadata": {
        "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
      },
      "source": [
        "**Q2.** This question provides some practice cleaning variables which have common problems.\n",
        "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.1\n",
        "bnb = pd.read_csv(\"/content/wrangling/assignment/data/airbnb_hw.csv\") # Read in csv file\n",
        "print(bnb['Price'].dtype) # Print the \"Price\" column data type.\n",
        "\n",
        "bnb['Price'] = bnb['Price'].str.replace(',', '').astype(int) # Replace commas with an empty string, then convert the resulting strings to integers.\n",
        "\n",
        "print(bnb['Price'].dtype)  # Reprint \"Price\" column data type to verify data has been cleaned.\n",
        "\n",
        "# I did not end up with any missing values."
      ],
      "metadata": {
        "id": "WCEzzlbKU3mE",
        "outputId": "7f56713c-9578-4450-8460-767640c1927c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "WCEzzlbKU3mE",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object\n",
            "int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Categorical variable: For the `./data/sharks.csv` data covered in the lecture, clean the \"Type\" variable as well as you can, and explain the choices you make."
      ],
      "metadata": {
        "id": "A69R9c10yzQH"
      },
      "id": "A69R9c10yzQH"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.2\n",
        "sharks = pd.read_csv(\"/content/wrangling/data/sharks.csv\") # Read in csv file\n",
        "print(sharks['Type'].value_counts(), '\\n')\n",
        "print(sharks['Type'].unique(), '\\n') # Print all unique values in the \"Type\" column\n",
        "\n",
        "sharks['Type'].replace(['Invalid','Questionable','Unconfirmed','Unverified',\"Under investigation\"], np.nan, inplace=True) # Replace all unknown values with np.nan\n",
        "sharks['Type'].replace(['Sea Disaster','Watercraft', 'Boating', 'Boat', 'Boatomg'], 'Watercraft', inplace=True) # Merge categories that have synonymous meanings\n",
        "\n",
        "print(sharks['Type'].value_counts(), '\\n') #Reprint all unique values in the \"Type\" column and their counts"
      ],
      "metadata": {
        "id": "y2alVA2yYsEP",
        "outputId": "01df0ba3-8b82-484e-c255-25a3d4522a53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "y2alVA2yYsEP",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unprovoked             4716\n",
            "Provoked                593\n",
            "Invalid                 552\n",
            "Sea Disaster            239\n",
            "Watercraft              142\n",
            "Boat                    109\n",
            "Boating                  92\n",
            "Questionable             10\n",
            "Unconfirmed               1\n",
            "Unverified                1\n",
            "Under investigation       1\n",
            "Boatomg                   1\n",
            "Name: Type, dtype: int64 \n",
            "\n",
            "['Unprovoked' 'Provoked' 'Questionable' 'Watercraft' 'Unconfirmed'\n",
            " 'Unverified' 'Invalid' 'Under investigation' 'Boating' 'Sea Disaster' nan\n",
            " 'Boat' 'Boatomg'] \n",
            "\n",
            "Unprovoked    4716\n",
            "Provoked       593\n",
            "Watercraft     583\n",
            "Name: Type, dtype: int64 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-28645262c646>:2: DtypeWarning: Columns (10,17,18,19,20,21,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  sharks = pd.read_csv(\"/content/wrangling/data/sharks.csv\") # Read in csv file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Dummy variable: For the pretrial data covered in the lecture, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`."
      ],
      "metadata": {
        "id": "OwkOL2WPy4oq"
      },
      "id": "OwkOL2WPy4oq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.3\n",
        "url = 'http://www.vcsc.virginia.gov/pretrialdataproject/October%202017%20Cohort_Virginia%20Pretrial%20Data%20Project_Deidentified%20FINAL%20Update_10272021.csv'\n",
        "trial = pd.read_csv(url,low_memory=False) # Read in data file\n",
        "print(trial['WhetherDefendantWasReleasedPretrial'].unique(), '\\n') # Print all unique values in the \"WhetherDefendantWasReleasedPretrial\" column\n",
        "\n",
        "trial['WhetherDefendantWasReleasedPretrial'].replace(9, np.nan, inplace=True) # Replace 9s with np.nan, because the codebook defines 9s as \"unclear\"\n",
        "\n",
        "print(trial['WhetherDefendantWasReleasedPretrial'].value_counts(), '\\n') #Reprint all unique values in the \"WhetherDefendantWasReleasedPretrial\" column and their counts"
      ],
      "metadata": {
        "id": "ti2ULBVpkEoJ",
        "outputId": "ddfe9507-45c4-4944-9865-b54a6681c135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ti2ULBVpkEoJ",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 0 1] \n",
            "\n",
            "1.0    19154\n",
            "0.0     3801\n",
            "Name: WhetherDefendantWasReleasedPretrial, dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
      ],
      "metadata": {
        "id": "pIMsubXFy9K9"
      },
      "id": "pIMsubXFy9K9"
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2.4\n",
        "sentence = trial['ImposedSentenceAllChargeInContactEvent']\n",
        "type = trial['SentenceTypeAllChargesAtConvictionInContactEvent']\n",
        "print(sentence.dtype)\n",
        "\n",
        "sentence = pd.to_numeric(sentence, errors='coerce') # Coerce all values to numeric\n",
        "sentence = sentence.mask(type == 4, 0) # Replace sentence with 0 when type ==4, because 4s are defined as pending/dismissed cases.\n",
        "sentence = sentence.mask(type == 9, np.nan) # Replace sentence with np.nan when type ==9, because 9s are defined as \"not applicable\"\n",
        "\n",
        "trial['ImposedSentenceAllChargeInContactEvent'] = sentence # Replace with cleaned data\n",
        "print(sentence.dtype)\n",
        "\n",
        "trial_subset = trial[['ImposedSentenceAllChargeInContactEvent','SentenceTypeAllChargesAtConvictionInContactEvent']] # View subset of cleaned data\n",
        "trial_subset\n",
        "\n",
        "del sentence, type # Delete temporary variables"
      ],
      "metadata": {
        "id": "lkK1P8kWsXFq",
        "outputId": "0e8a4b5d-f646-4224-e3c5-b62a3a3057b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lkK1P8kWsXFq",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object\n",
            "float64\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}